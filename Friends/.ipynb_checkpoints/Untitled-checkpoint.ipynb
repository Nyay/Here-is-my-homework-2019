{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим несколько переменных для того, чтобы составить материальню базу.\n",
    "\n",
    "**folds** – Это список папок, в которых хранятся наши тектсы, с которыми мы будем работать.\n",
    "\n",
    "**txts** – Список, в который мы поместим все наши тексты после обработки.\n",
    "\n",
    "**dir_line** – путь до нашей рабочей директори"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = ['Friends - season 1', 'Friends - season 2', 'Friends - season 3',\n",
    "         'Friends - season 4', 'Friends - season 5', 'Friends - season 6',\n",
    "         'Friends - season 7']\n",
    "\n",
    "txts = []\n",
    "\n",
    "dir_line = '/Users/macbook/Downloads/Friends/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию, которая будет чистить текст от всякой гадости.\n",
    "\n",
    "    1.Для очистки от знаков использую *string.punctuation*\n",
    "\n",
    "    2.Помимо этого в тексте есть и другия грязь, от которой необходимо избавиться.\n",
    "\n",
    "    3.Выполняю токенизацию текста и склеиваю все в один текст, *исключая числа*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    for el in tokens:\n",
    "        if el in string.punctuation:\n",
    "            tokens.remove(el)\n",
    "        if el == '...' or el == \"''\" or el == '—' or el == '«' or el == '»':\n",
    "            tokens.remove(el)\n",
    "    text = ' '.join([i for i in tokens if not i.isdigit()])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пройдемся по папкам и достанем все текста. Обработаем его и добавим в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fold in folds:\n",
    "    local_dir = list(os.walk(dir_line + fold))\n",
    "    local_path = str(local_dir[0][0])\n",
    "    for text in local_dir[0][2]:\n",
    "        if '.txt' in text and type(text) == str:\n",
    "            with open(local_path + '/' + text) as file:\n",
    "                txts.append(cleaning(file.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для составления терм-документ матрицы я использую ***CountVectorizer*** из *sklearn.feature_extraction.text*\n",
    "\n",
    "Тем самым составлю матрицу, где:\n",
    "\n",
    "    Столбцы – Это слова\n",
    "    Строки – Это документы\n",
    "\n",
    "Для удобства также преобразую матрицу в **DataFrame** при помощи Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "term_doc_matrix = vec.fit_transform(txts).toarray()\n",
    "term_doc_matrix_DataFrame = pd.DataFrame(term_doc_matrix,\n",
    "                                         columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 30829)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix_DataFrame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается 165 документов и 30829 слов.\n",
    "\n",
    "Напишем простую функцию Булева поиска, которая может искать только одно слово.\n",
    "\n",
    "Как я и говорил раньше, всвязи с форматом матрицы, необходимо только найти такие строки, в столбце соответсвующем патерну поиска стоит НЕ ноль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boolean_search(pattern):\n",
    "    try:\n",
    "        return term_doc_matrix_DataFrame[term_doc_matrix_DataFrame[pattern.lower()] != 0].index.tolist()[:5]\n",
    "    except KeyError:\n",
    "        return 'No pattern in DataSet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_search('Моника')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 6, 7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_search('Фиби')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде работает. Теперь займемся более сложным поиском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect(boolean_search('Моника'), boolean_search('Фиби'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boolean_search_type_r(pattern):\n",
    "    try:\n",
    "        return term_doc_matrix_DataFrame[term_doc_matrix_DataFrame[pattern.lower()] != 0].index.tolist()\n",
    "    except KeyError:\n",
    "        return 'No pattern in DataSet'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
