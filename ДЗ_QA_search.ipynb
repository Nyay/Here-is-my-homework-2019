{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ по поиску\n",
    "\n",
    "Привет! Вам надо реализивать поисковик на базе вопросов-ответов с сайта [pravoved.ru](https://pravoved.ru/questions-archive/).        \n",
    "Поиск должен работать на трех технологиях:       \n",
    "1. обратном индексе     \n",
    "2. word2vec         \n",
    "3. doc2vec      \n",
    "\n",
    "Вы должны понять, какой метод и при каких условиях эксперимента на этом корпусе работает лучше.          \n",
    "Для измерения качества поиска найдите точность (accuracy) выпадания правильного ответа на конкретный вопрос (в этой базе у каждого вопроса есть только один правильный ответ). Точность нужно измерить для всей базы.    \n",
    "При этом давайте считать, что выпал правильный ответ, если он попал в **топ-5** поисковой выдачи.\n",
    "\n",
    "> Сделайте ваш поиск максимально качественным, чтобы значение точности стремилось к 1.     \n",
    "Для этого можно поэкспериментировать со следующим:       \n",
    "- модель word2vec (можно брать любую из опен сорса или обучить свою)\n",
    "- способ получения вектора документа через word2vec: простое среднее арифметическое или взвешивать каждый вектор в соответствии с его tf-idf      \n",
    "- количество эпох у doc2vec (начинайте от 100)\n",
    "- предобработка документов для обучения doc2vec (удалять / не удалять стоп-слова)\n",
    "- блендинг методов поиска: соединить результаты обратного индекса и w2v, или (что проще) w2v и d2v\n",
    "\n",
    "На это задание отведем 10 дней. Дэдлайн сдачи до полуночи 12.10.\n",
    "\n",
    "Я правда старался(((((((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('qa_corpus.pkl', 'rb') as file:\n",
    "    qa_corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего в корпусе 1384 пары вопрос-ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый элемент блока это вопрос, второй - ответ на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nДобрый день.Мой сын гражданин Украины (ДНР),имеет вид на жительство в Р.Ф., кот.получил проживая с 2014 г. в Нижегородской области.В 2017г. переехал на постоянное место жительство в г.Ростов.Официально трудоустроился на одно из промышл.предприятий г.Ростова.Оформил временную регистрацию в Ростове.В УФМС предупредили,что по истечении 90 дней он должен либо постоянно прописаться либо покинуть территорию России.Прошу проконсультировать как быть дальше.(Вернуться домой в Донецк,но здесь идет война,работы нет.В Ростове он работает по специальности.Он инженер машиностроитель.)Временная прописка до 15 марта.  Если он сможет приобрести какую либо недвижимость,как долго будет решаться вопрос о его постоянной прописке в Ростове.Как в этом случае будет решаться вопрос с видом на жительство в Ростове? Не получится ли ,что приобретя квартиру,он не успеет в ней прописаться до окончании срока временной регистрации. С уважением Людмила Евгеньевна.\\n',\n",
       " 'Добрый вечер!Из Вашего вопроса вообще ничего не ясно.Ваш сын по ВНЖ в Нижегородской обл. сделал временную\\xa0 на 90 дней в Ростове? Так? Или в чем заключается вопрос?С ув., АлёнаМиграционный юристРостов-на-Дону ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну поехали...\n",
    "\n",
    "##  Word2Vec\n",
    "\n",
    "Как обычно вначале импортируем все необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "from pymystem3 import Mystem\n",
    "from gensim import matutils\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь берем нашу любимую модель, которая способна на все в нашем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '/Users/macbook/Downloads/araneum_none_fasttextcbow_300_5_2018/araneum_none_fasttextcbow_300_5_2018.model'\n",
    "w2v_model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь берем готовую функцию обработки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(input_text, del_stopwords=True, del_digit=True):\n",
    "    \"\"\"\n",
    "    :input: raw text\n",
    "        1. lowercase, del punctuation, tokenize\n",
    "        2. normal form\n",
    "        3. del stopwords\n",
    "        4. del digits\n",
    "    :return: lemmas\n",
    "    \"\"\"\n",
    "    russian_stopwords = set(stopwords.words('russian'))\n",
    "    words = [x.lower().strip(string.punctuation+'»«–…') for x in word_tokenize(input_text)]\n",
    "    lemmas = [mystem.lemmatize(x)[0] for x in words if x]\n",
    "\n",
    "    lemmas_arr = []\n",
    "    for lemma in lemmas:\n",
    "        if del_stopwords:\n",
    "            if lemma in russian_stopwords:\n",
    "                continue\n",
    "        if del_digit:\n",
    "            if lemma.isdigit():\n",
    "                continue\n",
    "        lemmas_arr.append(lemma)\n",
    "    return lemmas_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу напишем нашу функцию для построения вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2v_vector(word_list):\n",
    "    some = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            some.append(w2v_model.wv[str(word)])\n",
    "        except KeyError:\n",
    "            some.append(np.array([0] * 300))\n",
    "    return matutils.unitvec(np.array(sum(some) / len(word_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь построим словарь, где Ключ – **Вопрос**. Значение – **вектор вопроса** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 2.96 s, total: 18.5 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qa_vectors = defaultdict()\n",
    "\n",
    "for item in qa_corpus:\n",
    "    qa_vectors[item[1]] = w2v_vector(preprocessing(item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(v1, v2):\n",
    "    return np.dot(v1, v2)\n",
    "\n",
    "def search(query, number):\n",
    "    query_vector = w2v_vector(preprocessing(query))\n",
    "    local_data = defaultdict()\n",
    "    for item in qa_vectors:\n",
    "        local_data[item] = similarity(query_vector, qa_vectors[item]) \n",
    "    for el in sorted(local_data.items(), key=lambda kv: kv[1], reverse=True)[:number]:\n",
    "        yield el[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо проверить это все в полевых условиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1384 attempts, there are(is) 368 correct matches (score:0.2658959537572254)\n",
      "CPU times: user 22.6 s, sys: 1.62 s, total: 24.3 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "true = 0\n",
    "\n",
    "for qa in qa_corpus:\n",
    "    if qa[1] in list(search(qa[0], 5)):\n",
    "        true += 1\n",
    "\n",
    "print('For {} attempts, there are(is) {} correct matches (score:{})'.format(len(qa_corpus), true, true / len(qa_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный конец, давайте сделаем Okapi...\n",
    "\n",
    "# OkapiBM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.summarization import bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [preprocessing(x[1]) for x in qa_corpus]\n",
    "keys = [x[1] for x in qa_corpus]\n",
    "\n",
    "qa_data = bm25.BM25(texts)\n",
    "\n",
    "average_idf = sum(map(lambda k: float(qa_data.idf[k]),\n",
    "                      qa_data.idf.keys())) / len(qa_data.idf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def okapi25_search(query, number):\n",
    "    sim = defaultdict()\n",
    "\n",
    "    for key, value in zip(keys, qa_data.get_scores(query, average_idf)):\n",
    "        sim[key] = value\n",
    "\n",
    "    for el in sorted(sim.items(), key=lambda kv: kv[1], reverse=True)[:number]:\n",
    "        yield el[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1384 attempts, there are(is) 778 correct matches (score:0.5621387283236994)\n",
      "CPU times: user 30.7 s, sys: 1.67 s, total: 32.4 s\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "true = 0\n",
    "\n",
    "for qa in qa_corpus:\n",
    "    if qa[1] in list(okapi25_search(preprocessing(qa[0]), 5)):\n",
    "        true += 1\n",
    "\n",
    "print('For {} attempts, there are(is) {} correct matches (score:{})'.format(len(qa_corpus), true, true / len(qa_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaaaaaaany way оно работает, хоть 0.56... Не самый лучший скор... Наверное...\n",
    "\n",
    "Теперь опробуем...\n",
    "\n",
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2v_vector(word_list):\n",
    "    some = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            some.append(d2v_model.wv[str(word)])\n",
    "        except KeyError:\n",
    "            some.append(np.array([0] * 300))\n",
    "    return matutils.unitvec(np.array(sum(some) / len(word_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку обучаться модель Doc2Vec будет на данных, которые мы подготовим с помощью TaggedDocument, нам необходимо подготовить и почистить текст перед его загрузкой туда. Для этого немного изменим уже существующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2v_preprocessing(input_text, del_stopwords=True, del_digit=True):\n",
    "    \"\"\"\n",
    "    :input: raw text\n",
    "        1. lowercase, del punctuation, tokenize\n",
    "        2. normal form\n",
    "        3. del stopwords\n",
    "        4. del digits\n",
    "    :return: lemmas\n",
    "    \"\"\"\n",
    "    russian_stopwords = set(stopwords.words('russian'))\n",
    "    words = [x.lower().strip(string.punctuation+'»«–…') for x in word_tokenize(input_text)]\n",
    "    lemmas = [mystem.lemmatize(x)[0] for x in words if x]\n",
    "\n",
    "    lemmas_arr = []\n",
    "    for lemma in lemmas:\n",
    "        if del_stopwords:\n",
    "            if lemma in russian_stopwords:\n",
    "                continue\n",
    "        if del_digit:\n",
    "            if lemma.isdigit():\n",
    "                continue\n",
    "        lemmas_arr.append(lemma)\n",
    "    return ' '.join(lemmas_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получаем наши готовые данные и обучаем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate([d2v_preprocessing(x[1]) for x in qa_corpus])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created\n",
      "Model trained\n",
      "Model Saved\n",
      "CPU times: user 1min 20s, sys: 3.88 s, total: 1min 24s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 100\n",
    "vec_size = 300\n",
    "alpha = 0.025\n",
    "\n",
    "d2v_model = Doc2Vec(size=vec_size,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=1,\n",
    "                    dm =1)\n",
    "  \n",
    "d2v_model.build_vocab(tagged_data)\n",
    "\n",
    "print(\"Vocab created\")\n",
    "\n",
    "d2v_model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=epochs)\n",
    "print(\"Model trained\")\n",
    "d2v_model.alpha -= 0.0002\n",
    "d2v_model.min_alpha = model.alpha\n",
    "\n",
    "d2v_model.save(\"d2v_qa.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем вектора и начинаем нашу проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 2.91 s, total: 18.2 s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors = defaultdict()\n",
    "\n",
    "for qa in qa_corpus:\n",
    "    vectors[qa[1]] = d2v_vector(preprocessing(qa[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, result_len):\n",
    "    query_vector = d2v_vector(preprocessing(query))\n",
    "    local_data = defaultdict()\n",
    "    for item in vectors:\n",
    "        local_data[item] = similarity(query_vector, vectors[item]) \n",
    "    sort_data = sorted(local_data.items(), key=lambda kv: kv[1], reverse=True)[:result_len]\n",
    "    for el in sort_data:\n",
    "        yield el[0]\n",
    "\n",
    "def similarity(v1, v2):\n",
    "    return np.dot(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1384 attempts, there are(is) 420 correct matches (score:0.30346820809248554)\n",
      "CPU times: user 18.8 s, sys: 1.57 s, total: 20.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "true = 0\n",
    "\n",
    "for qa in qa_corpus:\n",
    "    if qa[1] in list(search(qa[0], 5)):\n",
    "        true += 1\n",
    "\n",
    "print('For {} attempts, there are(is) {} correct matches (score:{})'.format(len(qa_corpus), true, true / len(qa_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем совместить наши модели\n",
    "\n",
    "## Делаем смузи\n",
    "\n",
    "Word2Vec + Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Combine_search(query, result_len):\n",
    "    w2v_query = w2v_vector(preprocessing(query))\n",
    "    d2v_query = d2v_vector(preprocessing(query))\n",
    "    local_data = defaultdict()\n",
    "    for item in vectors:\n",
    "        local_data[item] = (similarity(d2v_query, vectors[item])  +\n",
    "                            similarity(w2v_query, qa_vectors[item])) / 2\n",
    "    sort_data = sorted(local_data.items(), key=lambda kv: kv[1], reverse=True)[:result_len]\n",
    "    for el in sort_data:\n",
    "        yield el[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1384 attempts, there are(is) 430 correct matches (score:0.3106936416184971)\n",
      "CPU times: user 33.8 s, sys: 3.02 s, total: 36.8 s\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "true = 0\n",
    "\n",
    "for qa in qa_corpus:\n",
    "    if qa[1] in list(Combine_search(qa[0], 5)):\n",
    "        true += 1\n",
    "\n",
    "print('For {} attempts, there are(is) {} correct matches (score:{})'.format(len(qa_corpus), true, true / len(qa_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, самый большой score мы получили с помощью алгоритма OkapiBM25. Второе место – блэндинг Word2Vec и Doc2Vec. И третье место – Чситый Doc2Vec."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
